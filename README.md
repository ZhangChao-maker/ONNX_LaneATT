# ONNX_LaneATT
This repository creates a onnx of [LaneATT](https://github.com/lucastabelini/LaneATT) for inference.not use torch cuda
Can use in cpu device
## gen onnx moel
see https://github.com/Yibin122/TensorRT-LaneATT
## inference 
```python
python3 main.py
```
![image](https://github.com/huashui-gif/ONNX_LaneATT/blob/main/out.jpg)

